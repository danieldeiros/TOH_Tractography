{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b4ade8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c6ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://dahernandez:34732b8f774d6def@ohswg.ottawahospital.on.ca:8080\"\n",
    "os.environ[\"https_proxy\"] = \"http://dahernandez:34732b8f774d6def@ohswg.ottawahospital.on.ca:8080\"\n",
    "import pydicom\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "from dipy.reconst.shm import CsaOdfModel\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import default_sphere\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.viz import actor, colormap, has_fury, window\n",
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.tracking.utils import random_seeds_from_mask, path_length\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.tracker import eudx_tracking\n",
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "from skimage.draw import polygon\n",
    "from skimage import measure\n",
    "from rt_utils import RTStructBuilder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80038d76",
   "metadata": {},
   "source": [
    "# DICOM to NIfTI (only needs to be ran once to convert the files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206db2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dir = Path(\"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/DICOM\")\n",
    "nifti_dir = Path(\"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/NIfTI\")\n",
    "\n",
    "nifti_dir.mkdir(parents=True, exist_ok=True) # make folder for NIFTI if it doesnt exist yet\n",
    "\n",
    "cmd = [\n",
    "    \"dcm2niix\",\n",
    "    \"-z\", \"y\",\n",
    "    \"-f\", \"%p_%s\",\n",
    "    \"-o\", str(nifti_dir),\n",
    "    str(dicom_dir)\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb4f1c",
   "metadata": {},
   "source": [
    "# Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211a1ed",
   "metadata": {},
   "source": [
    "## Extract data and perform segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9bfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names\n",
    "fname = \"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/NIfTI/ep2d_diff_mddw_ISO_1.5MM_6\"\n",
    "nifti_file = fname + \".nii.gz\"\n",
    "bval_file  = fname + \".bval\"\n",
    "bvec_file  = fname + \".bvec\"\n",
    "\n",
    "# Extract data\n",
    "data, affine, hardi_img = load_nifti(nifti_file, return_img = True)\n",
    "bvals, bvecs = read_bvals_bvecs(bval_file, bvec_file)\n",
    "\n",
    "# Make gradient table\n",
    "gtab = gradient_table(bvals, bvecs = bvecs)\n",
    "\n",
    "# Make brain mask\n",
    "data_masked, mask = median_otsu(data, vol_idx=range(data.shape[3]), numpass=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fe14b",
   "metadata": {},
   "source": [
    "## Create white matter mask with DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f521b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the diffusion tensor model\n",
    "tensor_model = TensorModel(gtab)\n",
    "tensor_fit = tensor_model.fit(data_masked)\n",
    "\n",
    "# Get FA map\n",
    "FA = tensor_fit.fa\n",
    "\n",
    "# Generate white matter mask using FA threshold\n",
    "# Typical FA threshold for white matter is between 0.2 - 0.3\n",
    "white_matter_mask = (FA > 0.15).astype(np.uint8) # paper uses 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e526d0",
   "metadata": {},
   "source": [
    "## Use CSA model and peaks_from_model and define stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efebcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CSA (Constant Solid Angle) model then peaks_from_model\n",
    "csa_model = CsaOdfModel(gtab, sh_order_max=4)\n",
    "csa_peaks = peaks_from_model(\n",
    "    csa_model, data, default_sphere, relative_peak_threshold=0.5, min_separation_angle=15, mask=white_matter_mask\n",
    ") # or relative_peak_threshold=0.8, min_seperation_angle=45 (from introduction to basic tracking tutorial)\n",
    "\n",
    "# Define stopping criterion\n",
    "stopping_criterion = ThresholdStoppingCriterion(FA, 0.15) # or csa_peaks.gfa, 0.25 (from introduction to basic tracking tutorial). paper uses FA, 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e358aa",
   "metadata": {},
   "source": [
    "## Obtain ROI anded with white matter mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2256f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTV', 'External']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'white_matter_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m external_mask = rtstruct.get_roi_mask_by_name(\u001b[33m\"\u001b[39m\u001b[33mExternal\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Combining roi and white matter masks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m roi_wm_mask = roi_mask.astype(\u001b[38;5;28mbool\u001b[39m) & \u001b[43mwhite_matter_mask\u001b[49m.astype(\u001b[38;5;28mbool\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'white_matter_mask' is not defined"
     ]
    }
   ],
   "source": [
    "# Using RT_Utils package\n",
    "\n",
    "# Paths\n",
    "dicom_mri_dir = Path(\"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/RayStationROIs\")  # Folder with MR DICOM slices (not the RTSTRUCT)\n",
    "rtstruct_path = Path(\"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/RayStationROIs/RS1.2.752.243.1.1.20250620111917393.3000.17511.dcm\")  # RTSTRUCT file\n",
    "\n",
    "# Load RTStruct\n",
    "rtstruct = RTStructBuilder.create_from(dicom_series_path=dicom_mri_dir, rt_struct_path=rtstruct_path)\n",
    "\n",
    "# List available ROI names\n",
    "print(rtstruct.get_roi_names())\n",
    "\n",
    "# Choose ROI to convert to NIfTI mask\n",
    "roi_name = \"GTV\"\n",
    "roi_mask = rtstruct.get_roi_mask_by_name(roi_name)  # 3D binary numpy array\n",
    "\n",
    "external_mask = rtstruct.get_roi_mask_by_name(\"External\")\n",
    "\n",
    "# Combining roi and white matter masks\n",
    "roi_wm_mask = roi_mask.astype(bool) & white_matter_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8475f1b",
   "metadata": {},
   "source": [
    "### Save to NIfTI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab8bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to NIfTI\n",
    "nifti_roi_dir = Path(\"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/RayStationROIs_NIfTI\") # define folder path\n",
    "nifti_roi_dir.mkdir(parents=True, exist_ok=True) # make folder for NIFTI if it doesnt exist yet\n",
    "\n",
    "nifti_roi_path = os.path.join(nifti_roi_dir, \"gtv_wm_mask.nii.gz\") # define file path\n",
    "nib.save(nib.Nifti1Image(roi_wm_mask.astype('uint8'), affine=affine), nifti_roi_path) # use same affine as from MRI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56220c",
   "metadata": {},
   "source": [
    "## Generate seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b299b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating seeds\n",
    "seeds = random_seeds_from_mask(roi_wm_mask, affine, seeds_count=1, seed_count_per_voxel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b6902",
   "metadata": {},
   "source": [
    "## Use EuDX tracking to create streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839cfb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using EuDX tracking for now. \n",
    "# Initialization of eudx_tracking. The computation happens in the next step.\n",
    "streamlines_generator = eudx_tracking(\n",
    "    seeds, stopping_criterion, affine, step_size=0.5, pam=csa_peaks, max_angle=60 # paper uses max_angle of 60\n",
    ")\n",
    "# Generate streamlines object\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "\n",
    "# Streamlines with x and y flipped for colors\n",
    "streamlines_flipped = streamlines.copy()\n",
    "streamlines_flipped[:][:, 0:2] = streamlines_flipped[:][:, 1::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cdf91c",
   "metadata": {},
   "source": [
    "## Show tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = True\n",
    "\n",
    "if has_fury:\n",
    "\n",
    "    streamlines_actor = actor.line(\n",
    "        streamlines, colors=colormap.line_colors(streamlines_flipped, cmap = \"rgb_standard\")\n",
    "    )\n",
    "\n",
    "    roi_actor = actor.contour_from_roi(\n",
    "        roi_wm_mask, affine=affine, opacity=0.5, color=(1, 0, 0) # red\n",
    "    ) \n",
    "\n",
    "    roi_actor_external = actor.contour_from_roi(\n",
    "        external_mask, affine=affine, opacity=0.5, color=(0, 0, 1) # blue\n",
    "    ) \n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(streamlines_actor)\n",
    "    scene.add(roi_actor)\n",
    "    scene.add(roi_actor_external)\n",
    "\n",
    "    # Save still images for this static example. Or for interactivity use\n",
    "    # window.record(scene=scene, out_path=\"tractogram_EuDX.png\", size=(800, 800))\n",
    "    if interactive:\n",
    "        window.show(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db219f3c",
   "metadata": {},
   "source": [
    "## Save tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft = StatefulTractogram(streamlines, hardi_img, Space.RASMM)\n",
    "save_trk(sft, \"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/NIfTI/tractogram_EuDX.trk\", streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81097f",
   "metadata": {},
   "source": [
    "# WMPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d6ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the data\n",
    "basedir = \"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/\" # folder containing nifti file with roi and trk file with streamlines\n",
    "\n",
    "# set the path to the roi and the streamlines (trk). and also save path\n",
    "roi_wm_pathfrag = 'RayStationROIs_NIfTI/gtv_wm_mask.nii.gz'\n",
    "trk_pathfrag = 'NIfTI/tractogram_EuDX.trk'\n",
    "save_pathfrag = 'NIfTI/WMPL_map.nii.gz'\n",
    "\n",
    "# combine folder path with file paths\n",
    "roi_wm_path = os.path.join(basedir, roi_wm_pathfrag)\n",
    "trk_path = os.path.join(basedir, trk_pathfrag)\n",
    "save_path = os.path.join(basedir, save_pathfrag)\n",
    "\n",
    "# load the streamlines from the trk file\n",
    "trk = nib.streamlines.load(trk_path) # load trk file\n",
    "streamlines = trk.streamlines; hdr = trk.header; trk_aff = trk.affine # streamlines, header info and affine\n",
    "\n",
    "# load the ROI/WM from the NIfTI file\n",
    "roi_wm_img = nib.load(roi_wm_path)\n",
    "roi_wm_mask = roi_wm_img.get_fdata()\n",
    "roi_wm_aff = roi_wm_img.affine\n",
    "\n",
    "# Compute path length per voxel # calculate the WMPL\n",
    "wmpl = path_length(streamlines, trk_aff, roi_wm_mask, fill_value=0)\n",
    "\n",
    "# save the WMPL as a NIfTI\n",
    "save_nifti(save_path, wmpl, trk_aff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa4ffe",
   "metadata": {},
   "source": [
    "### Show WMPL map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = True\n",
    "\n",
    "if has_fury:\n",
    "    \n",
    "    # Set path to WMPL NIfTI file\n",
    "    wmpl_path = \"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/NIfTI/WMPL_map.nii.gz\"\n",
    "\n",
    "    # Set path to ROI+WM NIfTI file\n",
    "    roi_wm_path = \"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Patient 1/RayStationROIs_NIfTI/gtv_wm_mask.nii.gz\"\n",
    "\n",
    "    # Load WMPL map\n",
    "    wmpl_img = nib.load(wmpl_path); wmpl_data = wmpl_img.get_fdata(); affine = wmpl_img.affine\n",
    "\n",
    "    # Load ROI+WM mask\n",
    "    roi_img = nib.load(roi_wm_path); roi_wm_mask = roi_img.get_fdata()\n",
    "\n",
    "    # mask where WMPL > 0\n",
    "    wmpl_mask = wmpl_data > 0\n",
    "\n",
    "    # wmpl_actor = actor.contour_from_roi(\n",
    "    #     wmpl_mask, affine=affine, opacity=0.5, color=(0, 1, 0) # green\n",
    "    # ) \n",
    "    # roi_actor = actor.contour_from_roi(\n",
    "    #     roi_wm_mask, affine=affine, opacity=0.5, color=(1, 0, 0) # red\n",
    "    # ) \n",
    "\n",
    "    # Extract voxel coordinates whete WMPL > 0\n",
    "    voxel_coords = np.array(np.nonzero(wmpl_mask)).T # shape (N,3)\n",
    "\n",
    "    # Get corresponding WMPL values at these voxels\n",
    "    values = wmpl_data[wmpl_mask]\n",
    "\n",
    "    # Map voxel coords to real world coordinates (RASMM)\n",
    "    ras_coords = nib.affines.apply_affine(wmpl_img.affine, voxel_coords) # affine from wmpl should be same as affines from before\n",
    "\n",
    "    # Create a colormap for WMPL values\n",
    "    cmap = colormap.create_colormap(values, name='hot')\n",
    "\n",
    "    # Create a point cloud actor with colors\n",
    "    points_actor = actor.point(\n",
    "        ras_coords, cmap, point_radius=1.5, opacity=0.75 # voxels are 1.5 mm in x,y,z\n",
    "        ) \n",
    "\n",
    "    # Create actor for \"external\"/\"brain\"\n",
    "    roi_actor_external = actor.contour_from_roi(\n",
    "        external_mask, affine=affine, opacity=0.5, color=(0, 0, 1) # blue\n",
    "    ) \n",
    "\n",
    "    # cmap_lut = colormap.colormap_lookup_table(scale_range=(values.min()/10, values.max()/10), hue_range=(0,0.08), saturation_range=(1,0), value_range=(0.5,1))\n",
    "    # # Create actor for scalar bar\n",
    "    # scalar_bar_actor = actor.scalar_bar(\n",
    "    #     lookup_table=cmap_lut, title = \"Minimum WMPL (cm)\"\n",
    "    #     )\n",
    "\n",
    "    colorbar_data = values.reshape(1, -1)\n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(points_actor)\n",
    "    scene.add(roi_actor_external)\n",
    "    # scene.add(wmpl_actor)\n",
    "    # scene.add(roi_actor)\n",
    "    # scene.add(scalar_bar_actor)\n",
    "\n",
    "    # Show plot\n",
    "    if interactive:\n",
    "        window.show(scene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
