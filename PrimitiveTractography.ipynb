{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed80bdb7",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c029bfc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be74cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://dahernandez:34732b8f774d6def@ohswg.ottawahospital.on.ca:8080\"\n",
    "os.environ[\"https_proxy\"] = \"http://dahernandez:34732b8f774d6def@ohswg.ottawahospital.on.ca:8080\"\n",
    "import pydicom\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "from dipy.reconst.shm import CsaOdfModel\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import default_sphere\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.viz import actor, colormap, has_fury, window\n",
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.tracking.utils import random_seeds_from_mask, path_length\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.tracker import eudx_tracking\n",
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "from rt_utils import RTStructBuilder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import re\n",
    "import ants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3718bf0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023f612",
   "metadata": {},
   "source": [
    "### Function to check if a folder path has all the required NIfTI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27faa6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a folder path has all the required NIfTI files\n",
    "def check_nifti_folder(path, bval_bvec_expected):\n",
    "    # First set flag to false\n",
    "    valid_folder = False\n",
    "\n",
    "    if path.is_dir():\n",
    "        # Define flags for file types we need\n",
    "        niigz_flag = False\n",
    "        bval_flag = False\n",
    "        bvec_flag = False\n",
    "        for file_path in path.rglob(\"*\"): # parses every file recursively\n",
    "            if not file_path.is_file():\n",
    "                continue\n",
    "            if str(file_path).lower().endswith(\".nii.gz\"):\n",
    "                niigz_flag = True\n",
    "            elif str(file_path).lower().endswith(\".bval\"):\n",
    "                bval_flag = True\n",
    "            elif str(file_path).lower().endswith(\".bvec\"):\n",
    "                bvec_flag = True\n",
    "\n",
    "        if bval_bvec_expected:\n",
    "            if niigz_flag and bval_flag and bvec_flag:\n",
    "                valid_folder = True # Set flag to indicate folder is valid to proceed\n",
    "                print(\"✅ NIfTI folder contains the necessary NIfTI files to proceed without conversion.\")\n",
    "            elif not niigz_flag and not bval_flag and not bvec_flag:\n",
    "                print(\"❌ NIfTI folder does not contain any of the necessary NIfTI files.\")\n",
    "            else:\n",
    "                incomplete = True # Set flag to indicate incomplete conversion\n",
    "                print(\"⚠️ NIfTI folder contains some of the necessary NIfTI files. Please delete the folder's contents to avoid errors.\")\n",
    "        elif not bval_bvec_expected:\n",
    "            if niigz_flag:\n",
    "                valid_folder = True # Set flag to indicate folder is valid to proceed\n",
    "                print(\"✅ NIfTI folder contains the necessary NIfTI file to proceed without conversion.\")\n",
    "            else:\n",
    "                print(\"❌ NIfTI folder does not contain the necessary NIfTI files.\")\n",
    "    else:\n",
    "        print(\"❌ NIfTI folder does not exist.\")\n",
    "\n",
    "    return valid_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a8da1",
   "metadata": {},
   "source": [
    "### Function to extract file name from a given folder of NIfTI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5c12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract file name from a given folder of NIfTI files\n",
    "def get_fname(path):\n",
    "    fname = [] # Set empty first\n",
    "    for file_path in path.rglob(\"*\"): # parses every file recursively\n",
    "        # Extract file name without extension and add to fname if unique\n",
    "        if str(file_path).lower().endswith(\".nii.gz\"): \n",
    "            if re.sub(r\"\\.nii\\.gz$\",\"\", file_path.name) not in fname:\n",
    "                fname.append(re.sub(r\"\\.nii\\.gz$\",\"\", file_path.name)) \n",
    "        elif str(file_path).lower().endswith(\".bval\"):\n",
    "            if re.sub(r\"\\.bval$\",\"\", file_path.name) not in fname:\n",
    "                fname.append(re.sub(r\"\\.bval$\",\"\", file_path.name)) \n",
    "        elif str(file_path).lower().endswith(\".bvec\"):\n",
    "            if re.sub(r\"\\.bvec$\",\"\", file_path.name) not in fname:\n",
    "                fname.append(re.sub(r\"\\.bvec$\",\"\", file_path.name)) \n",
    "\n",
    "    if len(fname) > 1:\n",
    "        print(\"❌ Too many NIfTI files in folder. Please only include NIfTI files of diffusion imaging MR scan.\")\n",
    "    elif len(fname) < 1:\n",
    "        print(\"❌ No NIfTI files found in folder.\")\n",
    "    else:\n",
    "        fname = fname[0]\n",
    "        print(\"✅ File name succesfully acquired.\")\n",
    "\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615db7e0",
   "metadata": {},
   "source": [
    "### Function to get exported RayStation file PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b19ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get exported RayStation file PATHS\n",
    "def rs_get_paths(path):\n",
    "\n",
    "    # Define lists to add file paths to\n",
    "    CT_File_Paths = []\n",
    "    RD_File_Paths = []\n",
    "    RP_File_Paths = []\n",
    "    RS_File_Paths = []\n",
    "    MR_File_Paths = []\n",
    "\n",
    "    for file in path.glob(\"*.dcm\"): # Go through every file in folder (non-recursively)\n",
    "        if file.is_file():\n",
    "            try: # Determine what type of file it is\n",
    "                if \"CT\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'CT':\n",
    "                    CT_File_Paths.append(file)\n",
    "                elif \"RD\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'RTDOSE':\n",
    "                    RD_File_Paths.append(file)\n",
    "                elif \"RP\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'RTPLAN':\n",
    "                    RP_File_Paths.append(file)\n",
    "                elif \"RS\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'RTSTRUCT':\n",
    "                    RS_File_Paths.append(file)\n",
    "                elif \"MR\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'MR':\n",
    "                    MR_File_Paths.append(file)\n",
    "                else:\n",
    "                    print(f\"Unknown DICOM file {file.name}\")\n",
    "            except:\n",
    "                print(f\"Skipped invalid DICOM: {file.name}\")\n",
    "\n",
    "    print(f\"Found {len(CT_File_Paths)+len(RD_File_Paths)+len(RP_File_Paths)+len(RS_File_Paths)+len(MR_File_Paths)} valid DICOM files\")\n",
    "\n",
    "    file_paths = {\n",
    "        \"CT_File_Paths\" : CT_File_Paths,\n",
    "        \"RD_File_Paths\" : RD_File_Paths,\n",
    "        \"RP_File_Paths\" : RP_File_Paths,\n",
    "        \"RS_File_Paths\" : RS_File_Paths,\n",
    "        \"MR_File_Paths\" : MR_File_Paths\n",
    "    }\n",
    "\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee907871",
   "metadata": {},
   "source": [
    "### Function to get exported RayStation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5fa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get exported RayStation files\n",
    "def rs_get_info(path):\n",
    "\n",
    "    # Define lists to add file paths to\n",
    "    CT_File_Paths = []\n",
    "    RD_File_Paths = []\n",
    "    RP_File_Paths = []\n",
    "    RS_File_Paths = []\n",
    "    MR_File_Paths = []\n",
    "\n",
    "    # Define lists to add file info to\n",
    "    CT_Files = []\n",
    "    RD_Files = []\n",
    "    RP_Files = []\n",
    "    RS_Files = []\n",
    "    MR_Files = []\n",
    "\n",
    "    for file in path.glob(\"*.dcm\"):\n",
    "        if file.is_file():\n",
    "            # print(f\"Found file: {file.name}\")\n",
    "            try:\n",
    "                if \"CT\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'CT':\n",
    "                    CT_Files.append(pydicom.dcmread(file)) \n",
    "                    CT_File_Paths.append(file)\n",
    "                elif \"RD\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'RTDOSE':\n",
    "                    RD_Files.append(pydicom.dcmread(file))\n",
    "                    RD_File_Paths.append(file)\n",
    "                elif \"RP\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'RTPLAN':\n",
    "                    RP_Files.append(pydicom.dcmread(file))\n",
    "                    RP_File_Paths.append(file)\n",
    "                elif \"RS\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'RTSTRUCT':\n",
    "                    RS_Files.append(pydicom.dcmread(file))\n",
    "                    RS_File_Paths.append(file)\n",
    "                elif \"MR\" in file.name.upper() and pydicom.dcmread(file, stop_before_pixels=True).Modality == 'MR':\n",
    "                    MR_Files.append(pydicom.dcmread(file))\n",
    "                    MR_File_Paths.append(file)\n",
    "                else:\n",
    "                    print(f\"Unknown DICOM file {file.name}\")\n",
    "            except:\n",
    "                print(f\"Skipped invalid DICOM: {file.name}\")\n",
    "\n",
    "    print(f\"Found {len(CT_Files)+len(RD_Files)+len(RP_Files)+len(RS_Files)+len(MR_Files)} valid DICOM files\")\n",
    "\n",
    "    file_paths = {\n",
    "        \"CT_File_Paths\" : CT_File_Paths,\n",
    "        \"RD_File_Paths\" : RD_File_Paths,\n",
    "        \"RP_File_Paths\" : RP_File_Paths,\n",
    "        \"RS_File_Paths\" : RS_File_Paths,\n",
    "        \"MR_File_Paths\" : MR_File_Paths\n",
    "    }\n",
    "\n",
    "    file_info = {\n",
    "        \"CT_Files\" : CT_Files,\n",
    "        \"RD_Files\" : RD_Files,\n",
    "        \"RP_Files\" : RP_Files,\n",
    "        \"RS_Files\" : RS_Files,\n",
    "        \"MR_Files\" : MR_Files\n",
    "    }\n",
    "\n",
    "    return file_info, file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbd733",
   "metadata": {},
   "source": [
    "### Function to convert from DICOM to NIfTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5120e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_to_nifti(dicom_dir, nifti_dir):\n",
    "    nifti_dir.mkdir(parents=True, exist_ok=True) # make folder for NIFTI if it doesnt exist yet\n",
    "\n",
    "    # Create command for dcm2niix\n",
    "    # -z y creates compressed (.gz) .nii files\n",
    "    # -f %p_%s defines output file name as %p (protocol name(DICOM tag 0018, 1030)) with %s (series(DICOM tag 0020, 0011))\n",
    "    # -o specifies the output directory of the NIfTI files\n",
    "    cmd = [\n",
    "        # \"dcm2niix\",\n",
    "        \"V:/Common/Staff Personal Folders/DanielH/RayStation_Scripts/Tractography/Subscripts/dcm2niix/dcm2niix.exe\",\n",
    "        \"-z\", \"y\",\n",
    "        \"-f\", \"%p_%s\",\n",
    "        \"-o\", str(nifti_dir),\n",
    "        str(dicom_dir)\n",
    "    ]\n",
    "\n",
    "    # Run this command in the terminal. Print any errors\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"STDOUT:\", e.stdout)\n",
    "        print(\"STDERR:\", e.stderr)\n",
    "        print(\"Return code:\", e.returncode)\n",
    "\n",
    "    print(\"✅ DICOM files successfully converted to NIfTI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b49b5e0",
   "metadata": {},
   "source": [
    "## Patient Folder Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa26df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory to be used\n",
    "base_dir = Path(\"V:/Common/Staff Personal Folders/DanielH/DICOM_Files/TractographyPatient/Case 1 RS/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b20472",
   "metadata": {},
   "source": [
    "## Show plots or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f97342",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f867d25",
   "metadata": {},
   "source": [
    "## DICOM to NIfTI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441b00e",
   "metadata": {},
   "source": [
    "### Check if NIfTI folder already exists with converted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e624d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NIfTI folder contains the necessary NIfTI files to proceed without conversion.\n"
     ]
    }
   ],
   "source": [
    "# Define NIfTI folder path\n",
    "nifti_dir = base_dir / \"NIfTI\"\n",
    "\n",
    "# Check if NIfTI folder has all the required files\n",
    "valid_folder = check_nifti_folder(nifti_dir, bval_bvec_expected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18cf7a0",
   "metadata": {},
   "source": [
    "### Make Proper DICOM Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff596f1",
   "metadata": {},
   "source": [
    "#### Identify if folder is valid for tractography (if any file has FA in its Series Description) and extract relevant files (most populous Series Instance UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b715424",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not valid_folder: # only proceed if NIfTI folder doesn't already contain necessary files\n",
    "  # Define folder containing raw DICOM files\n",
    "    dicom_raw_dir = base_dir / \"combined\"\n",
    "\n",
    "    # Define dictionary to contain files with a given UID\n",
    "    series_counts = defaultdict(list)\n",
    "\n",
    "    FA_flag = False # Set a flag to check if FA is found in any of the folder's file's SeriesDescriptions\n",
    "\n",
    "    for file_path in dicom_raw_dir.rglob(\"*\"): # parses every file recursively\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        try:\n",
    "            # Try to read as DICOM using force=True\n",
    "            ds = pydicom.dcmread(file_path, stop_before_pixels=True, force=True)\n",
    "\n",
    "            uid = getattr(ds, \"SeriesInstanceUID\", None) # Get UID\n",
    "            if uid: # if UID found, add to series_counts\n",
    "                series_counts[uid].append(file_path)\n",
    "\n",
    "            if \"FA\" in str(getattr(ds, \"SeriesDescription\", None)).upper():\n",
    "                FA_flag = True # Set FA flag to true if FA found in Series Description\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {file_path.name}: {e}\")\n",
    "\n",
    "\n",
    "    # Print whether FA flag true or false\n",
    "    if FA_flag:\n",
    "        print(\"\\n✅ FA found in SeriesDescription of at least one file in folder. Folder valid for tractography\")\n",
    "    else:\n",
    "        print(\"\\n❌ No FA found in SeriesDescription of any file in folder. Folder NOT valid for tractography\")\n",
    "\n",
    "    # Print UID counts\n",
    "    print(\"\\nFound SeriesInstanceUIDs:\")\n",
    "    for uid, files in series_counts.items():\n",
    "        print(f\"{uid} - {len(files)} files\")\n",
    "\n",
    "    # Identify most populous UID\n",
    "    if series_counts:\n",
    "        most_populous_uid = max(series_counts, key=lambda k: len(series_counts[k]))\n",
    "        print(f\"\\nMost populous UID: {most_populous_uid} ({len(series_counts[most_populous_uid])} slices)\")\n",
    "        relevant_files = series_counts[most_populous_uid] # assign files in most populous uid to relevant files\n",
    "    else:\n",
    "        print(\"\\nNo valid DICOMs found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e266f",
   "metadata": {},
   "source": [
    "#### Copy relevant files to new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f591a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not valid_folder: # only proceed if NIfTI folder doesn't already contain necessary files\n",
    "    output_dir = base_dir / \"DICOM\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True) # make folder for derived relevant DICOM files if it doesnt exist yet\n",
    "\n",
    "    for file_path in relevant_files:\n",
    "        try:\n",
    "            destination_path = output_dir / file_path.name # joins variables as path. (not division since path variable is involved)\n",
    "            if destination_path.is_file(): continue # Skip if path already has file\n",
    "            shutil.copy2(file_path, destination_path) # Copy file to folder if path doesn't have file\n",
    "        except Exception as e:\n",
    "            print(f\"Unable to copy {file_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f229d",
   "metadata": {},
   "source": [
    "### Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a32869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not valid_folder: # only proceed if NIfTI folder doesn't already contain necessary files\n",
    "    # Define paths to DICOM folder. NIfTI folder should already have path defined\n",
    "    dicom_dir = output_dir # Should have same path as output directory defined earlier\n",
    "    \n",
    "    dicom_to_nifti(dicom_dir, nifti_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45573bc5",
   "metadata": {},
   "source": [
    "# Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd53d63",
   "metadata": {},
   "source": [
    "## Load tracts if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b4b8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "trk_dir = base_dir / \"Tracts\"\n",
    "# trk_dir.mkdir(parents=True, exist_ok=True) # make folder if it doesnt exist yet\n",
    "trk_path = trk_dir / \"tractogram_EuDX.trk\"\n",
    "trk_path_gtv = trk_dir / \"tractogram_GTV_EuDX.trk\"\n",
    "\n",
    "if trk_path.is_file() and trk_path_gtv.is_file():\n",
    "    # Load the streamlines from the trk file\n",
    "    trk = nib.streamlines.load(trk_path) # load trk file\n",
    "    streamlines = trk.streamlines; trk_aff = trk.affine # streamlines and affine\n",
    "\n",
    "    trk_gtv = nib.streamlines.load(trk_path_gtv) # load trk file\n",
    "    streamlines_gtv = trk_gtv.streamlines; trk_gtv_aff = trk_gtv.affine # streamlines and affine\n",
    "\n",
    "    # Check that both affines are equal\n",
    "    assert np.array_equal(trk_aff, trk_gtv_aff), \"Affines from white matter tracts and GTV tracts are not matching.\"\n",
    "\n",
    "    # Set affine matrix\n",
    "    affine = trk_aff\n",
    "    \n",
    "    tracts_flag = True # Set flag to indicate tracts exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f26098",
   "metadata": {},
   "source": [
    "## Load white matter mask if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83afee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "rs_dir = base_dir / \"RayStation\" # Folder containing RayStation (RS) exports\n",
    "rs_rois_nii_dir = rs_dir / \"ROIs_NIfTI\"\n",
    "white_matter_mask_nii_path = rs_rois_nii_dir / \"white_matter_mask.nii.gz\" # define file path\n",
    "\n",
    "if white_matter_mask_nii_path.is_file():\n",
    "    # Load white matter mask\n",
    "    white_matter_mask_nii = nib.load(white_matter_mask_nii_path); white_matter_mask = white_matter_mask_nii.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb721962",
   "metadata": {},
   "source": [
    "## Obtain file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ef059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract file name\n",
    "fname = get_fname(nifti_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d8709",
   "metadata": {},
   "source": [
    "## Extract data and perform segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names\n",
    "nifti_file = str(nifti_dir / (fname + \".nii.gz\"))\n",
    "bval_file  = str(nifti_dir / (fname + \".bval\"))\n",
    "bvec_file  = str(nifti_dir / (fname + \".bvec\"))\n",
    "\n",
    "# Extract data\n",
    "data, affine, hardi_img = load_nifti(nifti_file, return_img = True)\n",
    "bvals, bvecs = read_bvals_bvecs(bval_file, bvec_file)\n",
    "\n",
    "# Make gradient table\n",
    "gtab = gradient_table(bvals, bvecs = bvecs)\n",
    "\n",
    "# Make brain mask\n",
    "data_masked, mask = median_otsu(data, vol_idx=range(data.shape[3]), numpass=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c92ca",
   "metadata": {},
   "source": [
    "## Create white matter mask with DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951de26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the diffusion tensor model\n",
    "tensor_model = TensorModel(gtab)\n",
    "tensor_fit = tensor_model.fit(data_masked)\n",
    "\n",
    "# Get FA map\n",
    "FA = tensor_fit.fa\n",
    "\n",
    "# Generate white matter mask using FA threshold\n",
    "# Typical FA threshold for white matter is between 0.2 - 0.3. Can use 0.25\n",
    "white_matter_mask = (FA > 0.15).astype(np.uint8) # paper uses 0.15\n",
    "white_matter_mask[:,:,:]=white_matter_mask[::-1,::-1,:] # reverse order in x and y directions to visualize like in RayStation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab13956",
   "metadata": {},
   "source": [
    "## Obtain ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41b49f",
   "metadata": {},
   "source": [
    "### Create folders for CT DICOM, MR DICOM, and RT Struct if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b57da55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 295 valid DICOM files\n",
      "Found 70 valid DICOM files\n",
      "Found 1 valid DICOM files\n"
     ]
    }
   ],
   "source": [
    "# Define Paths\n",
    "rs_dir = base_dir / \"RayStation\" # Folder containing RayStation (RS) exports\n",
    "rs_ct_dcm_dir = rs_dir / \"CT_DICOM\" # Folder containg RS CT DICOM exports\n",
    "rs_mr_dcm_dir = rs_dir / \"MR_DICOM\" # Folder containing RS MR DICOM exports\n",
    "rs_rois_dir = rs_dir / \"ROIs\" # Folder containing RS ROIs (in RT struct)\n",
    "\n",
    "# Flags to indicate whether folders contain necessary files\n",
    "rs_ct_dcm_flag = False\n",
    "rs_mr_dcm_flag = False\n",
    "rs_rois_flag = False\n",
    "\n",
    "# Check if folders exist, if they do, check if they contain the appropriate file type\n",
    "# Delete files in folders if they don't contain what we want to prepare for the movement of files into the proper folders\n",
    "if rs_ct_dcm_dir.is_dir():\n",
    "    file_paths = rs_get_paths(rs_ct_dcm_dir)\n",
    "    rs_ct_dcm_flag = True if file_paths[\"CT_File_Paths\"] else False\n",
    "    if not rs_ct_dcm_flag:\n",
    "        shutil.rmtree(rs_ct_dcm_dir)\n",
    "    \n",
    "if rs_mr_dcm_dir.is_dir():\n",
    "    file_paths = rs_get_paths(rs_mr_dcm_dir)\n",
    "    rs_mr_dcm_flag = True if file_paths[\"MR_File_Paths\"] else False\n",
    "    if not rs_mr_dcm_flag:\n",
    "        shutil.rmtree(rs_mr_dcm_dir)\n",
    "\n",
    "if rs_rois_dir.is_dir():\n",
    "    file_paths = rs_get_paths(rs_rois_dir)\n",
    "    rs_rois_flag = True if file_paths[\"RS_File_Paths\"] else False\n",
    "    if not rs_rois_flag:\n",
    "        shutil.rmtree(rs_rois_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef0b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flag to false first\n",
    "valid_folders = False\n",
    "\n",
    "if rs_ct_dcm_flag and rs_mr_dcm_flag and rs_rois_flag: # Continue if all folders valid\n",
    "    valid_folders = True\n",
    "else: # Create folders for missing file types\n",
    "    file_paths = rs_get_paths(rs_dir) # Get all file paths from original RayStation folder\n",
    "\n",
    "    if not file_paths[\"CT_File_Paths\"] or not file_paths[\"MR_File_Paths\"] or not file_paths[\"RS_File_Paths\"]:\n",
    "        raise ValueError(f\"No RayStation files found in {rs_dir}. \\nMay be missing CT files, MR files, or RS files, or a combination.\")\n",
    "    \n",
    "    if not rs_ct_dcm_flag:\n",
    "        rs_ct_dcm_dir.mkdir(parents=True, exist_ok=True) # make folder if it doesn't exist\n",
    "        for file in file_paths[\"CT_File_Paths\"]: # Get all files and move to new folder\n",
    "            # Move file to new folder\n",
    "            shutil.move(file, rs_ct_dcm_dir)\n",
    "        rs_ct_dcm_flag = True # Set flag to true when process complete\n",
    "\n",
    "    if not rs_mr_dcm_flag:\n",
    "        rs_mr_dcm_dir.mkdir(parents=True, exist_ok=True) # make folder if it doesn't exist\n",
    "        for file in file_paths[\"MR_File_Paths\"]: # Get all files and move to new folder\n",
    "            # Move file to new folder\n",
    "            shutil.move(file, rs_mr_dcm_dir)\n",
    "        rs_mr_dcm_flag = True # Set flag to true when process complete\n",
    "\n",
    "    if not rs_rois_flag:\n",
    "        rs_rois_dir.mkdir(parents=True, exist_ok=True) # make folder if it doesn't exist\n",
    "        for file in file_paths[\"RS_File_Paths\"]: # Get all files and move to new folder\n",
    "            # Move file to new folder\n",
    "            shutil.move(file, rs_rois_dir)\n",
    "        rs_rois_flag = True # Set flag to true when process complete\n",
    "\n",
    "    valid_folders = True # Set flag to true when all processes complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bb1a4",
   "metadata": {},
   "source": [
    "### Load the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfd2964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check if masks already exist\n",
    "if not valid_folders:\n",
    "    raise ValueError(\"Folders containing RayStation files not validated.\")\n",
    "\n",
    "# Define folder and paths\n",
    "rs_rois_nii_dir = rs_dir / \"ROIs_NIfTI\"\n",
    "rs_rois_nii_dir.mkdir(parents=True, exist_ok=True) # make folder if it doesnt exist yet\n",
    "gtv_mask_nii_path = rs_rois_nii_dir / \"gtv_mask.nii.gz\" # define file path\n",
    "external_mask_nii_path = rs_rois_nii_dir / \"external_mask.nii.gz\" # define file path\n",
    "brain_mask_nii_path = rs_rois_nii_dir / \"brain_mask.nii.gz\" # define file path\n",
    "white_matter_mask_nii_path = rs_rois_nii_dir / \"white_matter_mask.nii.gz\" # define file path\n",
    "\n",
    "if gtv_mask_nii_path.is_file() and external_mask_nii_path.is_file() and brain_mask_nii_path.is_file():\n",
    "    # Get masks from pre-defined files\n",
    "    gtv_mask_nii = nib.load(gtv_mask_nii_path); gtv_mask = gtv_mask_nii.get_fdata()\n",
    "    external_mask_nii = nib.load(external_mask_nii_path); external_mask = external_mask_nii.get_fdata()\n",
    "    brain_mask_nii = nib.load(brain_mask_nii_path); brain_mask = brain_mask_nii.get_fdata()\n",
    "    \n",
    "else:\n",
    "    # Using RT_Utils package\n",
    "\n",
    "    # Get path for RT Struct with ROIs\n",
    "    file_paths = rs_get_paths(rs_rois_dir)\n",
    "    rt_struct_path = file_paths[\"RS_File_Paths\"][0] # Should only be one RT Struct file\n",
    "\n",
    "    # Load RTStruct\n",
    "    rtstruct = RTStructBuilder.create_from(dicom_series_path=rs_ct_dcm_dir, rt_struct_path=rt_struct_path)\n",
    "\n",
    "    # List available ROI names\n",
    "    print(f\"ROI Names: {rtstruct.get_roi_names()}\")\n",
    "\n",
    "    # Choose ROI(s) to convert to NIfTI mask. Note that names must be exact\n",
    "    gtv_name = [name for name in rtstruct.get_roi_names() if \"GTV\" in name] # Get names that contain GTV\n",
    "    gtv_name = gtv_name[0] # Take first name from list of GTV names \n",
    "    gtv_mask = rtstruct.get_roi_mask_by_name(gtv_name)  # 3D binary numpy array\n",
    "    gtv_mask = np.transpose(gtv_mask, (1, 0, 2)) # change to [x y z]\n",
    "    gtv_mask = gtv_mask[:, ::-1, :] # flip y-axis to work properly for ANTs\n",
    "\n",
    "    external_mask = rtstruct.get_roi_mask_by_name(\"External\") # Get External\n",
    "    external_mask = np.transpose(external_mask, (1, 0, 2)) # change to [x y z]\n",
    "    external_mask = external_mask[:, ::-1, :] # flip y-axis to work properly for ANTs\n",
    "\n",
    "    brain_mask = rtstruct.get_roi_mask_by_name(\"Brain\") # Get Brain\n",
    "    brain_mask = np.transpose(brain_mask, (1, 0, 2)) # change to [x y z]\n",
    "    brain_mask = brain_mask[:, ::-1, :] # flip y-axis to work properly for ANTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582ff33",
   "metadata": {},
   "source": [
    "### Check if interpolation/image registration is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e588eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation flag: False\n"
     ]
    }
   ],
   "source": [
    "# First check if interpolation is needed. Flag is true when interpolation is needed\n",
    "interp_flag = True if gtv_mask.shape != white_matter_mask.shape else False\n",
    "print(f\"Interpolation flag: {interp_flag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae3ccf",
   "metadata": {},
   "source": [
    "### Convert CT scans to NIfTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8565184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_flag:\n",
    "    # Must be converted from DICOM to NIfTI so that ANTs can read the files.\n",
    "    # ANTs can only read NIfTI\n",
    "\n",
    "    rs_ct_nii_dir = rs_dir / \"CT_NIfTI\" # define folder path\n",
    "\n",
    "    # Check if NIfTI folder has all the required files\n",
    "    valid_folder = check_nifti_folder(rs_ct_nii_dir, bval_bvec_expected=False)\n",
    "\n",
    "    if not valid_folder:\n",
    "        dicom_to_nifti(rs_ct_dcm_dir, rs_ct_nii_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41caf9",
   "metadata": {},
   "source": [
    "### Convert MR scans from RS into nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef5d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NIfTI folder contains the necessary NIfTI file to proceed without conversion.\n"
     ]
    }
   ],
   "source": [
    "# Getting affine from MR no matter what. So need to convert MR to NIfTI (should be done already anyways)\n",
    "# Must be converted from DICOM to NIfTI so that ANTs can read the files.\n",
    "# ANTs can only read NIfTI\n",
    "\n",
    "rs_mr_nii_dir = rs_dir / \"MR_NIfTI\" # define folder path\n",
    "\n",
    "# Check if NIfTI folder has all the required files\n",
    "valid_folder = check_nifti_folder(rs_mr_nii_dir, bval_bvec_expected=False)\n",
    "\n",
    "if not valid_folder:\n",
    "    dicom_to_nifti(rs_mr_dcm_dir, rs_mr_nii_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841cb6d",
   "metadata": {},
   "source": [
    "### Load affines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07508c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_flag:\n",
    "    rs_ct_nii_fname = get_fname(rs_ct_nii_dir) # Acquire file name for ct scan\n",
    "    rs_ct_nii_fpath = str(rs_ct_nii_dir / (rs_ct_nii_fname + \".nii.gz\")) \n",
    "\n",
    "    # Extract affine\n",
    "    _, affine_ct= load_nifti(rs_ct_nii_fpath, return_img = False) # only care about affine here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "387bfae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File name succesfully acquired.\n"
     ]
    }
   ],
   "source": [
    "# Getting affine from MR no matter what\n",
    "rs_mr_nii_fname = get_fname(rs_mr_nii_dir) # Acquire file name for ct scan\n",
    "rs_mr_nii_fpath = str(rs_mr_nii_dir / (rs_mr_nii_fname + \".nii.gz\")) \n",
    "\n",
    "# Extract affine\n",
    "_, affine_mr= load_nifti(rs_mr_nii_fpath, return_img = False) # only care about affine here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26da28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(affine_mr, affine), \"Affines from raw MR and RayStation MR are not matching.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c164f",
   "metadata": {},
   "source": [
    "### Save ROIs as NIfTI files (for ANTs in next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a9e6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_flag:\n",
    "    # Save masks to NIfTI files\n",
    "    nib.save(nib.Nifti1Image(gtv_mask.astype('uint8'), affine=affine_ct), gtv_mask_nii_path) # use same affine as from CT\n",
    "    nib.save(nib.Nifti1Image(external_mask.astype('uint8'), affine=affine_ct), external_mask_nii_path) # use same affine as from CT\n",
    "    nib.save(nib.Nifti1Image(brain_mask.astype('uint8'), affine=affine_ct), brain_mask_nii_path) # use same affine as from CT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c6851",
   "metadata": {},
   "source": [
    "### Create image registration from CT to MR using ANTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b4ec1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_flag:\n",
    "    # Use ANTs to transform masks from CR to MR space\n",
    "\n",
    "    # First read NIfTI files with ANTs\n",
    "    ct_ants = ants.image_read(str(rs_ct_nii_fpath))\n",
    "    mr_ants = ants.image_read(str(rs_mr_nii_fpath)) # MR file exported from RayStation. NOT raw MR diffusion imaging\n",
    "    gtv_mask_ants_ct = ants.image_read(str(gtv_mask_nii_path))\n",
    "    external_mask_ants_ct = ants.image_read(str(external_mask_nii_path))\n",
    "    brain_mask_ants_ct = ants.image_read(str(brain_mask_nii_path))\n",
    "\n",
    "    # Register CT to MR\n",
    "    reg = ants.registration(fixed=mr_ants, moving=ct_ants, type_of_transform='Rigid')\n",
    "\n",
    "    # Apply transform to masks\n",
    "    gtv_mask_ants_mr = ants.apply_transforms(fixed=mr_ants, moving=gtv_mask_ants_ct, \n",
    "                                            transformlist=reg['fwdtransforms'], interpolator='nearestNeighbor')\n",
    "    external_mask_ants_mr = ants.apply_transforms(fixed=mr_ants, moving=external_mask_ants_ct, \n",
    "                                            transformlist=reg['fwdtransforms'], interpolator='nearestNeighbor')\n",
    "    brain_mask_ants_mr = ants.apply_transforms(fixed=mr_ants, moving=brain_mask_ants_ct, \n",
    "                                            transformlist=reg['fwdtransforms'], interpolator='nearestNeighbor')\n",
    "    \n",
    "    # Get masks from ants variables\n",
    "    gtv_mask = gtv_mask_ants_mr.numpy()[::-1,::-1,:] # reverse x and y axes to be aligned with white matter\n",
    "    external_mask = external_mask_ants_mr.numpy()[::-1,::-1,:] # reverse x and y axes to be aligned with white matter\n",
    "    brain_mask = brain_mask_ants_mr.numpy()[::-1,::-1,:] # reverse x and y axes to be aligned with white matter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d35702",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the affine transformation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m affine = ants.read_transform(\u001b[43mreg\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mfwdtransforms\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Print the transformation type\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTransform type:\u001b[39m\u001b[33m\"\u001b[39m, affine.transform_type)\n",
      "\u001b[31mNameError\u001b[39m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the affine transformation\n",
    "affine = ants.read_transform(reg['fwdtransforms'][0])\n",
    "\n",
    "# Print the transformation type\n",
    "print(\"Transform type:\", affine.transform_type)\n",
    "\n",
    "# Print the transformation matrix\n",
    "print(\"Transform matrix:\\n\", affine.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b925356",
   "metadata": {},
   "source": [
    "### Overlap white matter mask with brain mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebe086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap white matter mask with brain mask to make sure all white matter is within the brain\n",
    "white_matter_mask = white_matter_mask.astype(bool) & brain_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc50ee3",
   "metadata": {},
   "source": [
    "### Create mask of overlap between GTV and WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask overlapping WM with GTV\n",
    "gtv_wm_mask = gtv_mask.astype(bool) & white_matter_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee162c",
   "metadata": {},
   "source": [
    "### Save ROIs as NIfTI files (for good now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_flag:\n",
    "    # Save masks to NIfTI files\n",
    "    nib.save(nib.Nifti1Image(gtv_mask.astype('uint8'), affine=affine_mr), gtv_mask_nii_path) # use same affine as from MR\n",
    "    nib.save(nib.Nifti1Image(external_mask.astype('uint8'), affine=affine_mr), external_mask_nii_path) # use same affine as from MR\n",
    "    nib.save(nib.Nifti1Image(brain_mask.astype('uint8'), affine=affine_mr), brain_mask_nii_path) # use same affine as from MR\n",
    "    nib.save(nib.Nifti1Image(white_matter_mask.astype('uint8'), affine=affine_mr), white_matter_mask_nii_path) # use same affine as from MR\n",
    "\n",
    "    # Interpolation no longer needed\n",
    "    interp_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337dba1",
   "metadata": {},
   "source": [
    "## Use CSA model and peaks_from_model and define stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CSA (Constant Solid Angle) model then peaks_from_model\n",
    "csa_model = CsaOdfModel(gtab, sh_order_max=4)\n",
    "csa_peaks = peaks_from_model(\n",
    "    csa_model, data_masked, default_sphere, relative_peak_threshold=0.5, min_separation_angle=15, mask=white_matter_mask\n",
    ") # or relative_peak_threshold=0.8, min_seperation_angle=45 (from introduction to basic tracking tutorial)\n",
    "# from paper: relative_peak_threshold=0.5, min_separation_angle=15\n",
    "\n",
    "# Define stopping criterion\n",
    "stopping_criterion = ThresholdStoppingCriterion(FA, 0.15) \n",
    "# or csa_peaks.gfa, 0.25 (from introduction to basic tracking tutorial). paper uses FA, 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77047cdc",
   "metadata": {},
   "source": [
    "## Generate seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686caef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating seeds\n",
    "\n",
    "# Generating seeds on white matter\n",
    "seeds_wm = random_seeds_from_mask(white_matter_mask, affine, seeds_count=1, seed_count_per_voxel=True)\n",
    "# paper seeds all white matter voxels. not just the ones which coincide with the GTV (ROI)\n",
    "# so can use white_matter_mask or roi_wm_mask\n",
    "\n",
    "# Generating seeds on GTV\n",
    "seeds_gtv = random_seeds_from_mask(gtv_mask, affine, seeds_count=1, seed_count_per_voxel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd20731",
   "metadata": {},
   "source": [
    "## Use EuDX tracking to create streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using EuDX tracking for now. \n",
    "\n",
    "# Creating streamlines from all white matter and from GTV. First white matter.\n",
    "# Initialization of eudx_tracking. The computation happens in the next step.\n",
    "streamlines_generator_wm = eudx_tracking(\n",
    "    seeds_wm, stopping_criterion, affine, step_size=0.5, pam=csa_peaks, max_angle=60 # paper uses max_angle of 60\n",
    ")\n",
    "# Generate streamlines object\n",
    "streamlines_wm = Streamlines(streamlines_generator_wm)\n",
    "\n",
    "# Now creating streamlines from GTV\n",
    "streamlines_generator_gtv = eudx_tracking(\n",
    "    seeds_gtv, stopping_criterion, affine, step_size=0.5, pam=csa_peaks, max_angle=60 # paper uses max_angle of 60\n",
    ")\n",
    "# Generate streamlines object\n",
    "streamlines_gtv = Streamlines(streamlines_generator_gtv)\n",
    "\n",
    "# colors: red--> left to right, green--> front (anterior) to back (posterior), blue--> top to bottom\n",
    "# # Streamlines with x and y flipped for colors\n",
    "# streamlines_flipped = streamlines.copy()\n",
    "# streamlines_flipped[:][:, 0:2] = streamlines_flipped[:][:, 1::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff98bb",
   "metadata": {},
   "source": [
    "## Show tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25cf7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_fury:\n",
    "\n",
    "    from fury import utils\n",
    "\n",
    "    # streamlines_actor_wm = actor.line(\n",
    "    #     streamlines_wm, colors=colormap.line_colors(streamlines_wm, cmap = \"rgb_standard\"), opacity=0.25\n",
    "    # )\n",
    "\n",
    "    streamlines_actor_gtv = actor.line(\n",
    "        streamlines_gtv, colors=colormap.line_colors(streamlines_gtv, cmap = \"rgb_standard\"), opacity=1\n",
    "    )\n",
    "\n",
    "    gtv_actor = actor.contour_from_roi(\n",
    "        gtv_mask, affine=affine, opacity=0.75, color = (1,0,0) # red\n",
    "    )\n",
    "\n",
    "    # wm_actor = actor.contour_from_roi(\n",
    "    #     white_matter_mask, affine=affine, opacity=0.25, color=(1,1,1) # white\n",
    "    # )\n",
    "\n",
    "    # gtv_wm_actor = actor.contour_from_roi(\n",
    "    #     gtv_wm_mask, affine=affine, opacity=0.25, color=(0, 1, 0) # green\n",
    "    # ) \n",
    "\n",
    "    external_actor = actor.contour_from_roi(\n",
    "        external_mask, affine=affine, opacity=0.5, color=(0.676, 0.844, 0.898) # light blue\n",
    "    ) \n",
    "\n",
    "    # brain_actor = actor.contour_from_roi(\n",
    "    #     brain_mask, affine=affine, opacity=0.5, color=(1, 0.753, 0.796) # pink\n",
    "    # ) \n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    # scene.add(streamlines_actor_wm)\n",
    "    scene.add(streamlines_actor_gtv)\n",
    "    scene.add(gtv_actor)\n",
    "    # scene.add(wm_actor)\n",
    "    # scene.add(gtv_wm_actor)\n",
    "    scene.add(external_actor)\n",
    "    # scene.add(brain_actor)\n",
    "\n",
    "    # Define colours to show\n",
    "    colours = {\n",
    "        'GTV' : (1,0.1,0.1), # red\n",
    "        'External' : (0.676, 0.844, 0.898) # light blue\n",
    "    }\n",
    "\n",
    "    # Add custom legend (text + coloured squares)\n",
    "    legend_pos = np.array([150, 30, 0])\n",
    "    spacing = 20\n",
    "\n",
    "    for i, (label, colour) in enumerate(colours.items()):\n",
    "        # Add a small square actor as color indicator\n",
    "        square_actor = actor.sphere(centers=np.array([legend_pos + [0, -i*spacing, -i*spacing]]),\n",
    "                                    colors=np.array([colour]),\n",
    "                                    radii=10)\n",
    "        scene.add(square_actor)\n",
    "        \n",
    "        # Add the label as text next to it\n",
    "        # direction=None makes label follow camera\n",
    "        text_actor = actor.vector_text(text=label, pos=legend_pos + [100, -i*spacing, -i*spacing], scale=(20,20,20), direction=None, align_center=False, extrusion=10)\n",
    "        scene.add(text_actor)\n",
    "\n",
    "    # Add informational text\n",
    "    info_text = \"In tractography, the direction of streamlines is labelled by red, green, and blue, where...\" \\\n",
    "                 \"\\nRed indicates directions in the X axis: right to left or left to right.\" \\\n",
    "                 \"\\nGreen indicates directions in the Y axis: posterior to anterior or from anterior to posterior.\" \\\n",
    "                 \"\\nBlue indicates directions in the Z axis: inferior to superior or vice versa.\"\n",
    "    info_actor = actor.vector_text(text=info_text, pos=legend_pos + [100,-100,-100], scale=(5,5,5), direction=None, align_center=False, extrusion=10)\n",
    "    scene.add(info_actor)\n",
    "\n",
    "    # Save still images for this static example. Or for interactivity use\n",
    "    # window.record(scene=scene, out_path=\"tractogram_EuDX.png\", size=(800, 800))\n",
    "    if interactive:\n",
    "        window.show(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d442b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fury import window, actor\n",
    "scene = window.Scene()\n",
    "l = actor.vector_text(text='Hello')\n",
    "scene.add(l)\n",
    "window.show(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cb4f6",
   "metadata": {},
   "source": [
    "## Save tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81840f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define/create folder and path\n",
    "trk_dir = base_dir / \"Tracts\"\n",
    "trk_dir.mkdir(parents=True, exist_ok=True) # make folder if it doesnt exist yet\n",
    "trk_path = trk_dir / \"tractogram_EuDX.trk\"\n",
    "\n",
    "# Define tractogram and save\n",
    "sft = StatefulTractogram(streamlines_wm, hardi_img, Space.RASMM)\n",
    "save_trk(sft, str(trk_path), streamlines_wm)\n",
    "\n",
    "# Define path\n",
    "trk_path_gtv = trk_dir / \"tractogram_GTV_EuDX.trk\"\n",
    "\n",
    "# Define tractogram and save\n",
    "sft_gtv = StatefulTractogram(streamlines_gtv, hardi_img, Space.RASMM)\n",
    "save_trk(sft_gtv, str(trk_path_gtv), streamlines_gtv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf7c32",
   "metadata": {},
   "source": [
    "# WMPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef43a19",
   "metadata": {},
   "source": [
    "## Create WMPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995562f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the streamlines from the trk file\n",
    "trk = nib.streamlines.load(trk_path) # load trk file\n",
    "streamlines = trk.streamlines; hdr = trk.header; trk_aff = trk.affine # streamlines, header info and affine\n",
    "\n",
    "# Load the GTV from the NIfTI file\n",
    "gtv_img = nib.load(gtv_mask_nii_path)\n",
    "gtv_mask = gtv_img.get_fdata()\n",
    "gtv_aff = gtv_img.affine\n",
    "\n",
    "# Compute (minimum) path length per voxel # calculate the WMPL\n",
    "wmpl = path_length(streamlines, trk_aff, gtv_mask) # fill_value = 0 or -1? paper leaves blank\n",
    "\n",
    "# Define where to save WMPL\n",
    "wmpl_dir_nii = base_dir / \"WMPL/NIfTI\"\n",
    "wmpl_dir_nii.mkdir(parents=True, exist_ok=True) # make folder if it doesnt exist yet\n",
    "wmpl_path_nii = wmpl_dir_nii / \"WMPL_map.nii.gz\"\n",
    "\n",
    "# save the WMPL as a NIfTI\n",
    "save_nifti(wmpl_path_nii, wmpl, trk_aff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da909ca0",
   "metadata": {},
   "source": [
    "## Save WMPL as a DICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MR data used to make tracks\n",
    "# This dats should be same size (as in (x,y,z)) as the white matter mask\n",
    "# For example, (256,256,70) for both\n",
    "\n",
    "files, _ = rs_get_info(rs_mr_dcm_dir)\n",
    "slice_thickness = files[\"MR_Files\"][0].SliceThickness # take slice thickness from first MR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MR data\n",
    "Sorted_MR_Files = sorted(files[\"MR_Files\"], key=lambda file: float(file.ImagePositionPatient[2])) # sort files by z-axis. increasing towards the head\n",
    "# anatomical orientation type (0010,2210) absent so z-axis is increasing towards the head of the patient\n",
    "\n",
    "# Define where to save WMPL\n",
    "wmpl_dir_dcm = base_dir / \"WMPL/DICOM\"\n",
    "wmpl_dir_dcm.mkdir(parents=True, exist_ok=True) # make folder if it doesnt exist yet\n",
    "\n",
    "# create new series UID\n",
    "new_series_uid = pydicom.uid.generate_uid()\n",
    "\n",
    "for i in range(wmpl.shape[2]):  # For each slice\n",
    "    # ensure overlays properly with RayStation. Basically undoing what I did with ROIs.\n",
    "    slice_data = wmpl[::-1,:,i].astype(np.uint16).T  \n",
    "\n",
    "    # Get appropriate reference DICOM file\n",
    "    ref_dcm = Sorted_MR_Files[i]\n",
    "    dcm = ref_dcm.copy()\n",
    "\n",
    "    # Modify instance-specific metadata\n",
    "    dcm.InstanceNumber = i + 1\n",
    "    dcm.SeriesInstanceUID = new_series_uid\n",
    "    dcm.SOPInstanceUID = pydicom.uid.generate_uid()\n",
    "    dcm.PixelData = slice_data.tobytes()\n",
    "    dcm.Rows, dcm.Columns = slice_data.shape\n",
    "\n",
    "    dcm.save_as(wmpl_dir_dcm / f\"WMPL_slice_{i+1:03d}.dcm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717865f0",
   "metadata": {},
   "source": [
    "## Show WMPL map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_fury:\n",
    "\n",
    "    # Load WMPL map\n",
    "    wmpl_img = nib.load(wmpl_path_nii); wmpl_data = wmpl_img.get_fdata(); affine = wmpl_img.affine\n",
    "    \n",
    "    # mask where WMPL > 0\n",
    "    wmpl_mask = wmpl_data > 0\n",
    "\n",
    "    wmpl_actor = actor.contour_from_roi(\n",
    "        wmpl_mask, affine=affine, opacity=0.5, color=(0, 1, 0) # green\n",
    "    ) \n",
    "\n",
    "    # Extract voxel coordinates where WMPL > 0\n",
    "    voxel_coords = np.array(np.nonzero(wmpl_mask)).T # shape (N,3)\n",
    "\n",
    "    # Get corresponding WMPL values at these voxels\n",
    "    values = wmpl_data[wmpl_mask]\n",
    "\n",
    "    # Map voxel coords to real world coordinates (RASMM)\n",
    "    ras_coords = nib.affines.apply_affine(wmpl_img.affine, voxel_coords) # affine from wmpl should be same as affines from before\n",
    "\n",
    "    # Create a colormap for WMPL values\n",
    "    cmap = colormap.create_colormap(values, name='hot')\n",
    "\n",
    "    # Create a point cloud actor with colors\n",
    "    points_actor = actor.point(\n",
    "        ras_coords, cmap, point_radius=files[\"MR_Files\"][0].SliceThickness, opacity=0.75 # voxels are 1.5 mm (from what ive seen) in x,y,z (isotropic)\n",
    "    ) \n",
    "\n",
    "    # Create actor for external\n",
    "    external_actor = actor.contour_from_roi(\n",
    "        external_mask, affine=affine, opacity=0.5, color=(0, 0, 1) # blue\n",
    "    ) \n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(points_actor)\n",
    "    scene.add(external_actor)\n",
    "\n",
    "    # Show plot\n",
    "    if interactive:\n",
    "        window.show(scene)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
